{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:04.477184Z",
     "start_time": "2024-05-22T20:32:04.473128Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:04.495359Z",
     "start_time": "2024-05-22T20:32:04.492697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 1"
   ],
   "id": "3c594b1b42171a7d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:04.514048Z",
     "start_time": "2024-05-22T20:32:04.496385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset_x = ImageFolder(root='data/photo', transform=transform)\n",
    "dataset_y = ImageFolder(root='data/monet', transform=transform)\n",
    "\n",
    "train_loader_x = DataLoader(dataset_x, batch_size=batch_size, shuffle=True)\n",
    "train_loader_y = DataLoader(dataset_y, batch_size=batch_size, shuffle=True)"
   ],
   "id": "b148e4a106b1c350",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5fd490fa9fd5c552"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Architecture and losses",
   "id": "359601cb98ad138b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:04.518316Z",
     "start_time": "2024-05-22T20:32:04.515298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the LSGAN loss as in https://arxiv.org/pdf/1611.04076\n",
    "def lsgan_loss(pred, target):\n",
    "    return torch.mean((pred - target) ** 2)\n",
    "\n",
    "\n",
    "# Define the cycle consistency loss as in https://arxiv.org/pdf/1703.10593 \n",
    "def cycle_consistency_loss(real, reconstructed):\n",
    "    return torch.mean(torch.abs(real - reconstructed))"
   ],
   "id": "166edc3331d10773",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:04.525194Z",
     "start_time": "2024-05-22T20:32:04.518950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        model = resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)\n",
    "\n",
    "\n",
    "def compute_similarity(src_img, tgt_img, feature_extractor):\n",
    "    src_features = feature_extractor(src_img)\n",
    "    tgt_features = feature_extractor(tgt_img)\n",
    "    similarity = cosine_similarity(src_features, tgt_features)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def normalize_similarity(similarity):\n",
    "    normalized_similarity = (similarity - similarity.min()) / (similarity.max() - similarity.min())\n",
    "    return normalized_similarity\n",
    "\n",
    "\n",
    "def semantic_regularization(src_img, tgt_img, feature_extractor, beta_param):\n",
    "    similarity = compute_similarity(src_img, tgt_img, feature_extractor)\n",
    "    normalized_similarity = normalize_similarity(similarity)\n",
    "    regularization = beta_param * (1 - normalized_similarity)\n",
    "    return regularization\n"
   ],
   "id": "b0c9373df7af78b7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:04.535611Z",
     "start_time": "2024-05-22T20:32:04.526489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# U net inspired architecture\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            nn.InstanceNorm2d(64),  # Normalization layer, equivalent to batch norm but for style transfer\n",
    "            nn.ReLU(True),\n",
    "            # Downsampling\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Residual blocks - pretty deep network - avoid vanishing gradients\n",
    "            *[ResidualBlock(256) for _ in range(9)],\n",
    "            # Upsampling\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "# CNN with linear head\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ],
   "id": "406ade74aad43d9",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "$$\n",
    "L(G, F, D_X, D_Y) = \\mathcal{L}_{GAN}(G, D_Y, X, Y) + \\mathcal{L}_{GAN}(F, D_X, Y, X) + \\lambda \\mathcal{L}_{cyc}(G, F)\n",
    "$$\n",
    "from https://arxiv.org/pdf/1703.10593\n",
    "- update the discriminators with \\mathcal{L}_{GAN} (adversarial losses)\n",
    "- update the generators with \\mathcal{L}_{GAN} and \\mathcal{L}_{cyc} (adversarial and cycle consistency losses)"
   ],
   "id": "6a945901f1d412b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:04.722375Z",
     "start_time": "2024-05-22T20:32:04.536618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "from torch import optim\n",
    "import os\n",
    "\n",
    "G = Generator().to(device)\n",
    "F = Generator().to(device)\n",
    "Dx = Discriminator().to(device)\n",
    "Dy = Discriminator().to(device)\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "F_optimizer = optim.Adam(F.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "Dx_optimizer = optim.Adam(Dx.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "Dy_optimizer = optim.Adam(Dy.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "cycle_losses = []\n",
    "Dx_losses = []\n",
    "Dy_losses = []\n",
    "G_losses = []\n",
    "F_losses = []\n",
    "os.makedirs(\"weights\", exist_ok=True)\n",
    "\n",
    "\n",
    "def clear_loss_history():\n",
    "    cycle_losses.clear()\n",
    "    Dx_losses.clear()\n",
    "    Dy_losses.clear()\n",
    "    G_losses.clear()\n",
    "    F_losses.clear()\n",
    "\n",
    "\n",
    "def train(epochs, train_loader_x, train_loader_y, G, F, Dx, Dy, G_optimizer, F_optimizer, Dx_optimizer, Dy_optimizer,\n",
    "          cycle_losses, Dx_losses, Dy_losses, G_losses, F_losses, frozen_feature_extractor, beta_param, lambda_param=10, weight_dir=\"weights\"):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for i, (real_x, real_y) in enumerate(zip(train_loader_x, train_loader_y)):\n",
    "            real_x = real_x[0]\n",
    "            real_y = real_y[0]  # drop labels generated by ImageFolder\n",
    "            real_x = real_x.to(device)\n",
    "            real_y = real_y.to(device)\n",
    "\n",
    "            # Train Discriminators\n",
    "            Dx_optimizer.zero_grad()\n",
    "            Dy_optimizer.zero_grad()\n",
    "\n",
    "            fake_y = G(real_x)\n",
    "            fake_x = F(real_y)\n",
    "\n",
    "            # adversarial losses of the discriminators min log(1 - D(x)) + log(D(G(x))) => min (1 - D(x))^2 + D(G(x))^2\n",
    "            Dx_real_loss = lsgan_loss(Dx(real_x), torch.ones_like(Dx(real_x)))\n",
    "            Dx_fake_loss = lsgan_loss(Dx(fake_x.detach()), torch.zeros_like(Dx(fake_x)))\n",
    "            Dx_loss = (Dx_real_loss + Dx_fake_loss) * 0.5\n",
    "\n",
    "            Dy_real_loss = lsgan_loss(Dy(real_y), torch.ones_like(Dy(real_y)))\n",
    "            Dy_fake_loss = lsgan_loss(Dy(fake_y.detach()), torch.zeros_like(Dy(fake_y)))\n",
    "            Dy_loss = (Dy_real_loss + Dy_fake_loss) * 0.5\n",
    "\n",
    "            # backpropagate discriminator losses\n",
    "            Dx_loss.backward()\n",
    "            Dy_loss.backward()\n",
    "            Dx_optimizer.step()\n",
    "            Dy_optimizer.step()\n",
    "\n",
    "            # Train Generators\n",
    "            G_optimizer.zero_grad()\n",
    "            F_optimizer.zero_grad()\n",
    "\n",
    "            fake_y = G(real_x)\n",
    "            fake_x = F(real_y)\n",
    "\n",
    "            # adversarial losses of the generators max log(D(G(x))) => min (1 - D(G(x)))^2\n",
    "            G_loss = lsgan_loss(Dy(fake_y), torch.ones_like(Dy(fake_y)))\n",
    "            F_loss = lsgan_loss(Dx(fake_x), torch.ones_like(Dx(fake_x)))\n",
    "\n",
    "            cycle_x = F(fake_y)\n",
    "            cycle_y = G(fake_x)\n",
    "\n",
    "            # consistency loss - l1 norm between real and reconstructed images - min l1 error\n",
    "            cycle_x_loss = cycle_consistency_loss(real_x, cycle_x)\n",
    "            cycle_y_loss = cycle_consistency_loss(real_y, cycle_y)\n",
    "            total_cycle_loss = (cycle_x_loss + cycle_y_loss) * lambda_param + semantic_regularization(real_x, fake_y,\n",
    "                                                                                                      frozen_feature_extractor,\n",
    "                                                                                                      beta_param)\n",
    "\n",
    "            # backpropagate generator losses sum adversarial and cycle loss\n",
    "            total_G_loss = G_loss + total_cycle_loss\n",
    "            total_F_loss = F_loss + total_cycle_loss\n",
    "\n",
    "            total_G_loss.backward(\n",
    "                retain_graph=True)  # otherwise cannot backward pass total_F_loss -> reuse total_cycle loss\n",
    "            total_F_loss.backward()\n",
    "            G_optimizer.step()\n",
    "            F_optimizer.step()\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                print(f\"Epoch [{epoch}/{epochs}], Step [{i}/{len(train_loader_x)}], \"\n",
    "                      f\"cycle loss {total_cycle_loss.item()}\"\n",
    "                      f\"Dx Loss: {Dx_loss.item()}, Dy Loss: {Dy_loss.item()}, \"\n",
    "                      f\"G Loss: {total_G_loss.item()}, F Loss: {total_F_loss.item()}\")\n",
    "\n",
    "                cycle_losses.append(total_cycle_loss.item())\n",
    "                Dx_losses.append(Dx_loss.item())\n",
    "                Dy_losses.append(Dy_loss.item())\n",
    "                G_losses.append(total_G_loss.item())\n",
    "                F_losses.append(total_F_loss.item())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save(G.state_dict(), f\"{weight_dir}/{beta}_G_epoch_{epoch}.pth\")\n",
    "            torch.save(F.state_dict(), f\"{weight_dir}/{beta}_F_epoch_{epoch}.pth\")\n",
    "    return cycle_losses, Dx_losses, Dy_losses, G_losses, F_losses\n"
   ],
   "id": "af74e91d3289a2f6",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Experiments influence of lambda - cycle consistency loss \n",
    "lower is expected to encourage more style transfer wheres higher values should encourage more content preservation"
   ],
   "id": "ee0b249930bb90be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T20:32:05.330569Z",
     "start_time": "2024-05-22T20:32:04.723172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "\n",
    "lambdas = [1, 2, 5, 10, 20]\n",
    "betas = [10 ** (-4), 10 ** (-3), 10 ** (-2), 10 ** (-1), 1, 10]\n",
    "weight_dir = \"weights\"\n",
    "losses_dir = \"losses\"\n",
    "os.makedirs(weight_dir, exist_ok=True)\n",
    "os.makedirs(losses_dir, exist_ok=True)\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "num_epochs = 30\n",
    "feature_extractor = torchvision.models.resnet18(pretrained=True).eval().to(device)\n",
    "for beta in betas:\n",
    "    for l in lambdas:\n",
    "        weight_dir_for_lambda = f\"{weight_dir}/{l}\"\n",
    "        os.makedirs(weight_dir_for_lambda, exist_ok=True)\n",
    "        G = Generator().to(device)\n",
    "        F = Generator().to(device)\n",
    "        Dx = Discriminator().to(device)\n",
    "        Dy = Discriminator().to(device)\n",
    "    \n",
    "        G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        F_optimizer = optim.Adam(F.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        Dx_optimizer = optim.Adam(Dx.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        Dy_optimizer = optim.Adam(Dy.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    \n",
    "        cycle_losses, Dx_losses, Dy_losses, G_losses, F_losses = train(30, train_loader_x, train_loader_y, G, F, Dx, Dy,\n",
    "                                                                       G_optimizer, F_optimizer, Dx_optimizer, Dy_optimizer,\n",
    "                                                                       cycle_losses, Dx_losses, Dy_losses, G_losses,\n",
    "                                                                       F_losses, feature_extractor, beta_param=beta, lambda_param=l,\n",
    "                                                                       weight_dir=weight_dir_for_lambda)\n",
    "        clear_loss_history()\n",
    "        with open(f\"{weight_dir_for_lambda}/losses_{l}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"cycle_losses\": cycle_losses,\n",
    "                \"Dx_losses\": Dx_losses,\n",
    "                \"Dy_losses\": Dy_losses,\n",
    "                \"G_losses\": G_losses,\n",
    "                \"F_losses\": F_losses\n",
    "            }, f)"
   ],
   "id": "f90098e890ca09a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 27\u001B[0m\n\u001B[1;32m     24\u001B[0m Dx_optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(Dx\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlr, betas\u001B[38;5;241m=\u001B[39m(beta1, \u001B[38;5;241m0.999\u001B[39m))\n\u001B[1;32m     25\u001B[0m Dy_optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(Dy\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlr, betas\u001B[38;5;241m=\u001B[39m(beta1, \u001B[38;5;241m0.999\u001B[39m))\n\u001B[0;32m---> 27\u001B[0m cycle_losses, Dx_losses, Dy_losses, G_losses, F_losses \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mF\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m                                                               \u001B[49m\u001B[43mG_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mF_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDx_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDy_optimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m                                                               \u001B[49m\u001B[43mcycle_losses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDx_losses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDy_losses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mG_losses\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m                                                               \u001B[49m\u001B[43mF_losses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_param\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ml\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m                                                               \u001B[49m\u001B[43mweight_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_dir_for_lambda\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m clear_loss_history()\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mweight_dir_for_lambda\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/losses_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ml\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "Cell \u001B[0;32mIn[22], line 47\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epochs, train_loader_x, train_loader_y, G, F, Dx, Dy, G_optimizer, F_optimizer, Dx_optimizer, Dy_optimizer, cycle_losses, Dx_losses, Dy_losses, G_losses, F_losses, frozen_feature_extractor, beta_param, lambda_param, weight_dir)\u001B[0m\n\u001B[1;32m     44\u001B[0m Dy_optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     46\u001B[0m fake_y \u001B[38;5;241m=\u001B[39m G(real_x)\n\u001B[0;32m---> 47\u001B[0m fake_x \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreal_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# adversarial losses of the discriminators min log(1 - D(x)) + log(D(G(x))) => min (1 - D(x))^2 + D(G(x))^2\u001B[39;00m\n\u001B[1;32m     50\u001B[0m Dx_real_loss \u001B[38;5;241m=\u001B[39m lsgan_loss(Dx(real_x), torch\u001B[38;5;241m.\u001B[39mones_like(Dx(real_x)))\n",
      "File \u001B[0;32m/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[21], line 34\u001B[0m, in \u001B[0;36mGenerator.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/media/data/coding/mamba/envs/ssne/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[21], line 72\u001B[0m, in \u001B[0;36mResidualBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
